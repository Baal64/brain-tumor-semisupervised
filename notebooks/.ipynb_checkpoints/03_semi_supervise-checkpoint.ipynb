{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a96c71-f5e2-4eb4-aaad-e82221dcd509",
   "metadata": {},
   "source": [
    "# Analyse semi-supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b47ce8-4d5b-4a9d-ae76-2b38df22bf08",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1842794c-5b50-4bcf-b778-3790710fc95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongly labeled: (100, 2053)\n",
      "Weakly labeled: (1406, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                            filepath  has_label   label  \\\n",
       " 0  ..\\data\\mri_dataset_brain_cancer_oc\\avec_label...       True  cancer   \n",
       " 1  ..\\data\\mri_dataset_brain_cancer_oc\\avec_label...       True  cancer   \n",
       " 2  ..\\data\\mri_dataset_brain_cancer_oc\\avec_label...       True  cancer   \n",
       " 3  ..\\data\\mri_dataset_brain_cancer_oc\\avec_label...       True  cancer   \n",
       " 4  ..\\data\\mri_dataset_brain_cancer_oc\\avec_label...       True  cancer   \n",
       " \n",
       "         f_0       f_1       f_2       f_3       f_4       f_5       f_6  ...  \\\n",
       " 0  0.011641  0.014855  0.309468  0.112984  0.092031  0.000000  0.443308  ...   \n",
       " 1  0.047576  0.045124  0.004747  0.000000  0.000000  0.000000  0.003254  ...   \n",
       " 2  0.023101  0.067208  0.135242  0.000000  0.000000  0.000375  0.203493  ...   \n",
       " 3  0.003039  0.192276  0.042327  0.000000  0.004168  0.000000  1.024806  ...   \n",
       " 4  0.151541  0.046058  0.109404  0.000000  0.026315  0.008330  0.357026  ...   \n",
       " \n",
       "      f_2040    f_2041    f_2042    f_2043    f_2044    f_2045    f_2046  \\\n",
       " 0  0.062702  0.118318  0.034898  0.199230  1.656034  0.041210  0.073140   \n",
       " 1  0.123328  0.000000  0.027098  0.290650  0.242351  0.000000  0.000000   \n",
       " 2  0.127119  0.000000  0.102672  0.980460  0.702292  0.000000  0.000000   \n",
       " 3  0.017233  0.060294  0.020966  0.134899  0.357556  0.000686  0.011123   \n",
       " 4  0.005454  0.010853  0.042849  0.361198  0.324573  0.012139  0.001569   \n",
       " \n",
       "      f_2047  label_num  target  \n",
       " 0  0.369943          1       1  \n",
       " 1  0.000000          1       1  \n",
       " 2  0.000000          1       1  \n",
       " 3  0.063624          1       1  \n",
       " 4  0.194653          1       1  \n",
       " \n",
       " [5 rows x 2053 columns],\n",
       "                                             filepath  target weak_label\n",
       " 0  ..\\data\\mri_dataset_brain_cancer_oc\\sans_label...       1     cancer\n",
       " 1  ..\\data\\mri_dataset_brain_cancer_oc\\sans_label...       0     normal\n",
       " 2  ..\\data\\mri_dataset_brain_cancer_oc\\sans_label...       0     normal\n",
       " 3  ..\\data\\mri_dataset_brain_cancer_oc\\sans_label...       0     normal\n",
       " 4  ..\\data\\mri_dataset_brain_cancer_oc\\sans_label...       1     cancer)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chargement des features + labels forts\n",
    "df_features = pd.read_parquet(\"../data/brain_features_resnet50.parquet\")\n",
    "\n",
    "# Données fortement labellisées (100 images)\n",
    "df_strong = df_features[df_features[\"has_label\"] == True].copy()\n",
    "df_strong[\"target\"] = df_strong[\"label_num\"].astype(int)  # 0 normal, 1 cancer\n",
    "\n",
    "# Données faiblement labellisées (pseudo-labels à partir de KMeans)\n",
    "df_weak = pd.read_parquet(\"../data/brain_weak_labels_kmeans.parquet\").copy()\n",
    "df_weak.rename(columns={\"weak_label_num\": \"target\"}, inplace=True)\n",
    "df_weak[\"target\"] = df_weak[\"target\"].astype(int)\n",
    "\n",
    "print(\"Strongly labeled:\", df_strong.shape)\n",
    "print(\"Weakly labeled:\", df_weak.shape)\n",
    "\n",
    "df_strong.head(), df_weak.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104832d7-f146-412a-91d1-ab9d80f7a454",
   "metadata": {},
   "source": [
    "## Split train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6768f95-223a-4c0a-a87f-f32cba765471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fort: (80, 2053)\n",
      "Test fort: (20, 2053)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(target\n",
       " 0    40\n",
       " 1    40\n",
       " Name: count, dtype: int64,\n",
       " target\n",
       " 1    10\n",
       " 0    10\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_strong, test_strong = train_test_split(\n",
    "    df_strong,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_strong[\"target\"]\n",
    ")\n",
    "\n",
    "print(\"Train fort:\", train_strong.shape)\n",
    "print(\"Test fort:\", test_strong.shape)\n",
    "train_strong[\"target\"].value_counts(), test_strong[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe067752-3a5f-41ff-959e-59913d4a22dc",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader (images, pas features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b18db45b-f981-418e-8f5b-6541617b7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Transforms d'entraînement / test (ImageNet)\n",
    "image_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "class MRICNNDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"filepath\"]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = int(row[\"target\"])\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acca201-8a6d-4143-8994-8086116e91b3",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c85173-36d9-405f-b18e-08bdd1852e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 88)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_strong_ds = MRICNNDataset(train_strong, transform=image_transforms[\"train\"])\n",
    "test_strong_ds  = MRICNNDataset(test_strong,  transform=image_transforms[\"test\"])\n",
    "weak_ds         = MRICNNDataset(df_weak,      transform=image_transforms[\"train\"])\n",
    "\n",
    "train_strong_loader = DataLoader(train_strong_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader         = DataLoader(test_strong_ds,  batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "weak_loader         = DataLoader(weak_ds,         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "len(train_strong_loader), len(test_loader), len(weak_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ad334-c78b-4ea3-aaf4-5a1160392dc3",
   "metadata": {},
   "source": [
    "## Modèle CNN : ResNet adapté à 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fef2a76a-38f2-4169-9796-bdd105cd3a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "def create_model(freeze_backbone=True):\n",
    "    weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "    model = resnet50(weights=weights)\n",
    "\n",
    "    # Remplacer la couche finale pour 2 classes\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, 2)\n",
    "\n",
    "    if freeze_backbone:\n",
    "        for name, param in model.named_parameters():\n",
    "            if not name.startswith(\"fc.\"):\n",
    "                param.requires_grad = False\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20fffc-b654-4a6a-945c-8d337aceb60d",
   "metadata": {},
   "source": [
    "## Fonctions d'entrainement & d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf76fd3e-7c54-435e-b4c4-415441fedec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for imgs, labels in dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    return acc, f1, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f15e9a-8e72-4e46-9dc9-4774bb7ead43",
   "metadata": {},
   "source": [
    "##  Baseline : entrainement supervisé uniquement sur formtement labellisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f238d843-a265-474c-a7ab-d80fdce0fd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/8 - loss=0.6454 - acc=0.550 - f1=0.182\n",
      "[Baseline] Epoch 2/8 - loss=0.5250 - acc=0.700 - f1=0.571\n",
      "[Baseline] Epoch 3/8 - loss=0.4456 - acc=0.800 - f1=0.750\n",
      "[Baseline] Epoch 4/8 - loss=0.3645 - acc=0.850 - f1=0.824\n",
      "[Baseline] Epoch 5/8 - loss=0.3319 - acc=0.850 - f1=0.824\n",
      "[Baseline] Epoch 6/8 - loss=0.2754 - acc=0.900 - f1=0.889\n",
      "[Baseline] Epoch 7/8 - loss=0.3115 - acc=0.950 - f1=0.952\n",
      "[Baseline] Epoch 8/8 - loss=0.2495 - acc=0.950 - f1=0.952\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 8\n",
    "\n",
    "baseline_model = create_model(freeze_backbone=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(baseline_model, train_strong_loader, optimizer, criterion, device)\n",
    "    acc, f1, cm = evaluate(baseline_model, test_loader, device)\n",
    "    print(f\"[Baseline] Epoch {epoch+1}/{num_epochs} - loss={train_loss:.4f} - acc={acc:.3f} - f1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd011abe-8292-4b24-b4cb-1bb02677ed97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.95,\n",
       " 0.9523809523809523,\n",
       " array([[ 9,  1],\n",
       "        [ 0, 10]], dtype=int64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_acc, baseline_f1, baseline_cm = evaluate(baseline_model, test_loader, device)\n",
    "baseline_acc, baseline_f1, baseline_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3408337-6c3d-4d8d-8f4e-572d438d863b",
   "metadata": {},
   "source": [
    "## Semi-supervisé : faible puis fort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3668f-17e0-4de8-9c1d-aca5383296fe",
   "metadata": {},
   "source": [
    "### Phase 1 : entrainement du jeu faible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4c8e298-2847-45f4-9519-c2d0c9b8b732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Semi phase 1 - weak] Epoch 1/5 - loss=0.4888 - acc=0.600 - f1=0.333\n",
      "[Semi phase 1 - weak] Epoch 2/5 - loss=0.3619 - acc=0.750 - f1=0.667\n",
      "[Semi phase 1 - weak] Epoch 3/5 - loss=0.3409 - acc=0.750 - f1=0.667\n",
      "[Semi phase 1 - weak] Epoch 4/5 - loss=0.3330 - acc=0.750 - f1=0.667\n",
      "[Semi phase 1 - weak] Epoch 5/5 - loss=0.3209 - acc=0.800 - f1=0.750\n"
     ]
    }
   ],
   "source": [
    "semi_model = create_model(freeze_backbone=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(semi_model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs_weak = 5\n",
    "\n",
    "for epoch in range(num_epochs_weak):\n",
    "    train_loss = train_one_epoch(semi_model, weak_loader, optimizer, criterion, device)\n",
    "    acc, f1, cm = evaluate(semi_model, test_loader, device)\n",
    "    print(f\"[Semi phase 1 - weak] Epoch {epoch+1}/{num_epochs_weak} - loss={train_loss:.4f} - acc={acc:.3f} - f1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e51827d-8ba7-431e-ba21-d6a10afdde4d",
   "metadata": {},
   "source": [
    "### Phase 2 : entrainement du jeu fort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "905c25a2-6c66-4099-95e4-d348fc86a448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Semi phase 2 - strong] Epoch 1/5 - loss=0.3714 - acc=0.900 - f1=0.889\n",
      "[Semi phase 2 - strong] Epoch 2/5 - loss=0.3817 - acc=0.900 - f1=0.900\n",
      "[Semi phase 2 - strong] Epoch 3/5 - loss=0.3296 - acc=0.850 - f1=0.857\n",
      "[Semi phase 2 - strong] Epoch 4/5 - loss=0.3219 - acc=0.850 - f1=0.857\n",
      "[Semi phase 2 - strong] Epoch 5/5 - loss=0.3334 - acc=0.850 - f1=0.857\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(semi_model.parameters(), lr=5e-4)\n",
    "num_epochs_strong = 5\n",
    "\n",
    "for epoch in range(num_epochs_strong):\n",
    "    train_loss = train_one_epoch(semi_model, train_strong_loader, optimizer, criterion, device)\n",
    "    acc, f1, cm = evaluate(semi_model, test_loader, device)\n",
    "    print(f\"[Semi phase 2 - strong] Epoch {epoch+1}/{num_epochs_strong} - loss={train_loss:.4f} - acc={acc:.3f} - f1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c340e-4406-4991-bba2-8a7261667454",
   "metadata": {},
   "source": [
    "### Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32ed7a41-3021-496f-b2ea-9eba8aa42b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85,\n",
       " 0.8571428571428571,\n",
       " array([[8, 2],\n",
       "        [1, 9]], dtype=int64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_acc, semi_f1, semi_cm = evaluate(semi_model, test_loader, device)\n",
    "semi_acc, semi_f1, semi_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c43409-36f5-4bb3-a615-2a8cc1df2623",
   "metadata": {},
   "source": [
    "| Modèle                  | Données d'entraînement                               | Accuracy (test) | F1-score (test) |\n",
    "|-------------------------|------------------------------------------------------|-----------------|-----------------|\n",
    "| CNN supervisé (baseline) | Train fortement labellisé uniquement                | X.XXX           | Y.YYY           |\n",
    "| CNN semi-supervisé      | Faiblement labellisé puis finetune fort labellisé   | A.AAA           | B.BBB           |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
